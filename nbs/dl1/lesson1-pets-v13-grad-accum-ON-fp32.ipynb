{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Accumulation ON - FP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_device = 1\n",
    "defaults.device = torch.device(f'cuda:{gpu_device}')\n",
    "torch.cuda.set_device(gpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 8\n",
    "N_STEP = 4  # grad accumulation for n steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS); path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_anno = path/'annotations'\n",
    "path_img = path/'images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = get_image_files(path_img)\n",
    "fnames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccumulateOptimWrapper(OptimWrapper):\n",
    "    def step(self):          pass\n",
    "    def zero_grad(self):      pass\n",
    "    def real_step(self):      super().step()\n",
    "    def real_zero_grad(self): super().zero_grad()\n",
    "        \n",
    "def acc_create_opt(self, lr:Floats, wd:Floats=0.):\n",
    "        \"Create optimizer with `lr` learning rate and `wd` weight decay.\"\n",
    "        self.opt = AccumulateOptimWrapper.create(self.opt_func, lr, self.layer_groups,\n",
    "                                         wd=wd, true_wd=self.true_wd, bn_wd=self.bn_wd)\n",
    "        \n",
    "@dataclass\n",
    "class AccumulateStep(LearnerCallback):\n",
    "    \"\"\"\n",
    "    Does accumlated step every nth step by accumulating gradients\n",
    "    \"\"\"\n",
    "    def __init__(self, learn:Learner, n_step:int = 1):\n",
    "        super().__init__(learn)\n",
    "        self.n_step = n_step\n",
    " \n",
    "    def on_train_begin(self, **kwargs):\n",
    "        \"check if loss is reduction\"\n",
    "        if self.loss_func.reduction == \"mean\":\n",
    "             print(\"For better gradients consider 'reduction=sum'\")\n",
    "        \n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        \"init samples and batches, change optimizer\"\n",
    "        self.acc_samples = 0\n",
    "        self.acc_batches = 0\n",
    "        \n",
    "    def on_batch_begin(self, last_input, last_target, **kwargs):\n",
    "        \"accumulate samples and batches\"\n",
    "        self.acc_samples += last_input.shape[0]\n",
    "        self.acc_batches += 1\n",
    "        print(f\"At batch {self.acc_batches}\")\n",
    "        \n",
    "    def on_backward_end(self, **kwargs):\n",
    "        \"step if number of desired batches accumulated, reset samples\"\n",
    "        if (self.acc_batches % self.n_step) == 0:\n",
    "            for p in (self.learn.model.parameters()):\n",
    "                if p.requires_grad: p.grad.div_(self.acc_samples)\n",
    "    \n",
    "            print(f\"Stepping at batch: {self.acc_batches}\")\n",
    "            self.learn.opt.real_step()\n",
    "            self.learn.opt.real_zero_grad()\n",
    "            self.acc_samples = 0\n",
    "    \n",
    "    def on_epoch_end(self, **kwargs):\n",
    "        \"step the rest of the accumulated grads\"\n",
    "        self.learn.opt.real_step()\n",
    "        self.learn.opt.real_zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_create_opt = Learner.create_opt\n",
    "def turn_off_accumulation(): Learner.create_opt = original_create_opt\n",
    "def turn_on_accumulation(): Learner.create_opt = acc_create_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = re.compile(r'/([^/]+)_\\d+.jpg$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageDataBunch.from_name_re(path_img, fnames, pat, ds_tfms=get_transforms(), size=224, bs=BS\n",
    "                                  ).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(rows=2, figsize=(7,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training: resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learner():\n",
    "    turn_on_accumulation()\n",
    "    learn = create_cnn(data=data, arch=models.resnet34, metrics=error_rate,\n",
    "                       callback_fns=[partial(AccumulateStep, n_step=N_STEP)])\n",
    "    learn.loss_func = CrossEntropyFlat(reduction=\"sum\")\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner() \n",
    "learn.lr_find() # pick lr\n",
    "learn.recorder.plot()\n",
    "learn = get_learner() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unfreezing, fine-tuning, and learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(2, max_lr=slice(1e-6,1e-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training: resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageDataBunch.from_name_re(path_img, fnames, pat, ds_tfms=get_transforms(),\n",
    "                                   size=299, bs=BS).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learner():\n",
    "    turn_on_accumulation()\n",
    "    learn = create_cnn(data=data, arch=models.resnet50, metrics=error_rate,\n",
    "                       callback_fns=[partial(AccumulateStep, n_step=N_STEP)])\n",
    "    learn.loss_func = CrossEntropyFlat(reduction=\"sum\")\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner() \n",
    "learn.lr_find() # pick lr\n",
    "learn.recorder.plot()\n",
    "learn = get_learner() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unfreeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(3, max_lr=slice(1e-6,1e-4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
